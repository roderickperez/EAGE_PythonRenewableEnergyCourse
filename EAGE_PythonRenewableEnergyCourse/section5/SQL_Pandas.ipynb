{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL + Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will cover a step-by-step example to integrate the energy production data stored in a database (SQLite) and then using Python to analyze and plot the data. This guide walks through each step, from loading CSV data into an SQLite database to querying and plotting the energy production data for different countries.\n",
    "\n",
    "This sections includes downloading the data from individual `.csv` files, loading them into a SQLite database, and visualizing the energy production using Python.\n",
    "\n",
    "This guide shows how to:\n",
    "1. Download CSV files from Eurostat.\n",
    "2. Load data into a SQLite database.\n",
    "3. Use Python to query and visualize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download the Data from Eurostat\n",
    "\n",
    "The datasets are available on the Eurostat website under [Energy Statistics](https://ec.europa.eu/eurostat/web/energy). Letâ€™s assume the data files have been downloaded and stored in your `~/Downloads` folder as `.csv` files.\n",
    "\n",
    "For this example, we are using the following datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    'coal': '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_coal.xlsx',\n",
    "    'nonRenewables': '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_combustionFuels_nonRenewables.xlsx',\n",
    "    'renewables': '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_combustionFuels_Renewables.xlsx',\n",
    "    'geothermal': '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_geothermal.xlsx',\n",
    "    'hydro': '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_hydro.xlsx',\n",
    "    'naturalGas': '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_naturalGas.xlsx',\n",
    "    'nuclear': '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_nuclear.xlsx',\n",
    "    'oil': '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_oil.xlsx',\n",
    "    'otherRenewables': '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_otherRenewables.xlsx',\n",
    "    'solar': '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_solar.xlsx',\n",
    "    'wind': '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_wind.xlsx'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite database (it will be created if it doesn't exist)\n",
    "db_path = 'coal_energy_data.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Check and Create the SQLite Database\n",
    "\n",
    "Before beginning, the code checks if the SQLite database (coal_energy_data.db) already exists. If it does, the existing database file is deleted to ensure you are working with a fresh database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database coal_energy_data.db already exists. Deleting it...\n",
      "Database coal_energy_data.db has been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Check if the database file exists\n",
    "if os.path.exists(db_path):\n",
    "    print(f\"Database {db_path} already exists. Deleting it...\")\n",
    "    os.remove(db_path)  # Delete the existing database file\n",
    "    print(f\"Database {db_path} has been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a new SQLite connection\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterward, the database is recreated by establishing a connection to the SQLite file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Load Data from Excel into SQLite\n",
    "\n",
    "The coal energy data is loaded from an Excel file into a Pandas DataFrame. The raw data is then stored in the SQLite database as the initial step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the coal dataset\n",
    "euroStat_coal = pd.read_excel(file_paths['coal'], sheet_name='coal', skiprows=range(0, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the raw data in the SQLite database\n",
    "euroStat_coal.to_sql('euroStat_coal', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Remove the First Two Rows\n",
    "\n",
    "Since the first two rows contain irrelevant information, such as metadata or unnecessary headers, they are removed using an SQL DELETE operation based on ROWID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first two rows (index 0 and 1)\n",
    "cursor.execute(\"DELETE FROM euroStat_coal WHERE ROWID IN (1, 2);\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Drop Unnecessary Columns\n",
    "\n",
    "Some columns in the data may have names starting with 'Unnamed', which indicate they are placeholders. Since SQLite does not directly support dropping columns, the workflow selects only the necessary columns and recreates a new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns where the name starts with 'Unnamed'\n",
    "cursor.execute(\"PRAGMA table_info(euroStat_coal);\")\n",
    "columns_info = cursor.fetchall()\n",
    "columns_to_keep = [col[1] for col in columns_info if not col[1].startswith('Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new table with only the required columns\n",
    "cursor.execute(f\"\"\"\n",
    "    CREATE TABLE euroStat_coal_cleaned_v2 AS\n",
    "    SELECT {', '.join(columns_to_keep)}\n",
    "    FROM euroStat_coal;\n",
    "\"\"\")\n",
    "cursor.execute(\"DROP TABLE euroStat_coal;\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Replace Invalid Values\n",
    "\n",
    "The data contains invalid values (:), which are replaced with NULL values in SQL. This ensures that the dataset is clean for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace invalid values (':' -> NULL)\n",
    "for column in columns_to_keep[1:]:  # Skip 'Country' column\n",
    "    cursor.execute(f\"\"\"\n",
    "        UPDATE euroStat_coal_cleaned_v2\n",
    "        SET \"{column}\" = NULLIF(\"{column}\", ':');\n",
    "    \"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Rename Columns to Date Format\n",
    "\n",
    "The column names are updated to represent proper dates (e.g., 2016-01, 2016-02, etc.). If the \"Country\" column does not exist in the cleaned table, it is added, and the final cleaned table is created with the new date-based column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 'Country' column.\n"
     ]
    }
   ],
   "source": [
    "# Rename columns with date formats (2016-01, 2016-02, ... , 2024-07)\n",
    "date_columns = pd.date_range(start='2016-01', end='2024-07', freq='MS').strftime('%Y-%m').tolist()\n",
    "\n",
    "# Ensure the columns_to_keep matches the new date columns\n",
    "new_columns = ['Country'] + date_columns\n",
    "\n",
    "# Check if \"Country\" column exists in the cleaned table\n",
    "cursor.execute(\"PRAGMA table_info(euroStat_coal_cleaned_v2);\")\n",
    "columns_info = cursor.fetchall()\n",
    "if \"Country\" not in [col[1] for col in columns_info]:\n",
    "    print(\"Adding 'Country' column.\")\n",
    "    # Recreate the table with the 'Country' column\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE euroStat_coal_cleaned_temp AS\n",
    "        SELECT \"TIME\" AS Country, * FROM euroStat_coal_cleaned_v2;\n",
    "    \"\"\")\n",
    "    cursor.execute(\"DROP TABLE euroStat_coal_cleaned_v2;\")\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE euroStat_coal_cleaned_v2 AS\n",
    "        SELECT Country, * FROM euroStat_coal_cleaned_temp;\n",
    "    \"\"\")\n",
    "    cursor.execute(\"DROP TABLE euroStat_coal_cleaned_temp;\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7e2a78bb6bc0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns by recreating the table with the updated date-based column names\n",
    "cursor.execute(f\"\"\"\n",
    "    CREATE TABLE euroStat_coal_cleaned_final AS\n",
    "    SELECT Country, {', '.join([f'\"{old_col}\" AS \"{new_col}\"' for old_col, new_col in zip(columns_to_keep[1:], date_columns)])}\n",
    "    FROM euroStat_coal_cleaned_v2;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the intermediate table and rename the final table back to the original cleaned table\n",
    "cursor.execute(\"DROP TABLE euroStat_coal_cleaned_v2;\")\n",
    "cursor.execute(\"ALTER TABLE euroStat_coal_cleaned_final RENAME TO euroStat_coal;\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Query and Verify Data\n",
    "\n",
    "Finally, the cleaned data is queried to verify that the transformations have been applied correctly. The first few rows of the cleaned data are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n"
     ]
    }
   ],
   "source": [
    "# Query the cleaned data\n",
    "df_coal_cleaned = pd.read_sql_query(\"SELECT * FROM euroStat_coal LIMIT 5;\", conn)\n",
    "print(df_coal_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Close the SQLite Connection\n",
    "\n",
    "Once all operations are complete, the SQLite connection is closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Summary\n",
    "\n",
    "1.\tCheck and Create the SQLite Database:\n",
    "â€¢\tThe code first checks if the SQLite database already exists. If it does, the existing database is deleted to ensure a fresh start.\n",
    "2.\tLoad Data from Excel into SQLite:\n",
    "â€¢\tThe coal energy data is loaded from an Excel file into a Pandas DataFrame and stored in the SQLite database.\n",
    "3.\tRemove the First Two Rows:\n",
    "â€¢\tThe first two rows of the dataset, which contain irrelevant information, are removed using SQL commands based on ROWID.\n",
    "4.\tDrop Unnecessary Columns:\n",
    "â€¢\tColumns whose names start with â€˜Unnamedâ€™ are considered unnecessary and are removed. A new table is created with only the required columns.\n",
    "5.\tReplace Invalid Values:\n",
    "â€¢\tInvalid values represented by â€˜:â€™ are replaced with NULL to clean the data.\n",
    "6.\tRename Columns to Date Format:\n",
    "â€¢\tThe column names are updated to reflect proper date formats (e.g., 2016-01, 2016-02), and if the Country column is missing, it is added.\n",
    "7.\tQuery and Verify Data:\n",
    "â€¢\tThe cleaned data is queried from the SQLite database to ensure the transformations have been applied correctly.\n",
    "8.\tClose the SQLite Connection:\n",
    "â€¢\tThe connection to the SQLite database is closed once all operations are complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat for all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_energy_data_individual_db(file_paths):\n",
    "    \"\"\"\n",
    "    This function processes the energy production data for multiple datasets (coal, geothermal, wind, etc.)\n",
    "    by loading data from Excel, cleaning it, and saving it to individual SQLite databases.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_paths: Dictionary containing dataset names and file paths.\n",
    "    \"\"\"\n",
    "    \n",
    "    for dataset, file_path in file_paths.items():\n",
    "        db_name = f'{dataset}_energy_data.db'  # Create a separate DB for each dataset\n",
    "        \n",
    "        # Step 1: Check if the database file exists, delete if it does\n",
    "        if os.path.exists(db_name):\n",
    "            print(f\"Database {db_name} already exists. Deleting it...\")\n",
    "            os.remove(db_name)  # Delete the existing database file\n",
    "            print(f\"Database {db_name} has been deleted.\")\n",
    "        \n",
    "        # Now create a new SQLite connection for this dataset\n",
    "        conn = sqlite3.connect(db_name)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        print(f\"Processing dataset: {dataset}\")\n",
    "        \n",
    "        # Step 2: Load data from Excel\n",
    "        data = pd.read_excel(file_path, sheet_name=dataset, skiprows=range(0, 8))\n",
    "        \n",
    "        # Step 3: Store the raw data in the SQLite database\n",
    "        data.to_sql(f'{dataset}', conn, if_exists='replace', index=False)\n",
    "        \n",
    "        # Step 4: Remove the first two rows\n",
    "        cursor.execute(f\"DELETE FROM {dataset} WHERE ROWID IN (1, 2);\")\n",
    "        conn.commit()\n",
    "        \n",
    "        # Step 5: Drop columns where the name starts with 'Unnamed'\n",
    "        cursor.execute(f\"PRAGMA table_info({dataset});\")\n",
    "        columns_info = cursor.fetchall()\n",
    "        columns_to_keep = [col[1] for col in columns_info if not col[1].startswith('Unnamed')]\n",
    "        \n",
    "        # Create a new table with only the required columns\n",
    "        cursor.execute(f\"\"\"\n",
    "            CREATE TABLE {dataset}_cleaned_v2 AS\n",
    "            SELECT {', '.join(columns_to_keep)}\n",
    "            FROM {dataset};\n",
    "        \"\"\")\n",
    "        cursor.execute(f\"DROP TABLE {dataset};\")\n",
    "        conn.commit()\n",
    "        \n",
    "        # Step 6: Replace invalid values (':' -> NULL)\n",
    "        for column in columns_to_keep[1:]:  # Skip 'Country' column\n",
    "            cursor.execute(f\"\"\"\n",
    "                UPDATE {dataset}_cleaned_v2\n",
    "                SET \"{column}\" = NULLIF(\"{column}\", ':');\n",
    "            \"\"\")\n",
    "        conn.commit()\n",
    "        \n",
    "        # Step 7: Rename columns with date formats (2016-01, 2016-02, ..., 2024-07)\n",
    "        date_columns = pd.date_range(start='2016-01', end='2024-07', freq='MS').strftime('%Y-%m').tolist()\n",
    "        \n",
    "        # Ensure the columns_to_keep matches the new date columns\n",
    "        new_columns = ['Country'] + date_columns\n",
    "        \n",
    "        # Check if \"Country\" column exists in the cleaned table\n",
    "        cursor.execute(f\"PRAGMA table_info({dataset}_cleaned_v2);\")\n",
    "        columns_info = cursor.fetchall()\n",
    "        if \"Country\" not in [col[1] for col in columns_info]:\n",
    "            print(\"Adding 'Country' column.\")\n",
    "            # Recreate the table with the 'Country' column\n",
    "            cursor.execute(f\"\"\"\n",
    "                CREATE TABLE {dataset}_cleaned_temp AS\n",
    "                SELECT \"TIME\" AS Country, * FROM {dataset}_cleaned_v2;\n",
    "            \"\"\")\n",
    "            cursor.execute(f\"DROP TABLE {dataset}_cleaned_v2;\")\n",
    "            cursor.execute(f\"\"\"\n",
    "                CREATE TABLE {dataset}_cleaned_v2 AS\n",
    "                SELECT Country, * FROM {dataset}_cleaned_temp;\n",
    "            \"\"\")\n",
    "            cursor.execute(f\"DROP TABLE {dataset}_cleaned_temp;\")\n",
    "        conn.commit()\n",
    "        \n",
    "        # Rename columns by recreating the table with the updated date-based column names\n",
    "        cursor.execute(f\"\"\"\n",
    "            CREATE TABLE {dataset}_cleaned_final AS\n",
    "            SELECT Country, {', '.join([f'\"{old_col}\" AS \"{new_col}\"' for old_col, new_col in zip(columns_to_keep[1:], date_columns)])}\n",
    "            FROM {dataset}_cleaned_v2;\n",
    "        \"\"\")\n",
    "        \n",
    "        # Drop the intermediate table and rename the final table back to the original cleaned table\n",
    "        cursor.execute(f\"DROP TABLE {dataset}_cleaned_v2;\")\n",
    "        cursor.execute(f\"ALTER TABLE {dataset}_cleaned_final RENAME TO {dataset};\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Step 8: Query and verify the cleaned data\n",
    "        df_cleaned = pd.read_sql_query(f\"SELECT * FROM {dataset} LIMIT 5;\", conn)\n",
    "        print(f\"Cleaned data for {dataset}:\")\n",
    "        print(df_cleaned)\n",
    "        \n",
    "        # Close the connection after processing the current dataset\n",
    "        conn.close()\n",
    "        print(f\"Finished processing {dataset}. Database saved as {db_name}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database coal_energy_data.db already exists. Deleting it...\n",
      "Database coal_energy_data.db has been deleted.\n",
      "Processing dataset: coal\n",
      "Adding 'Country' column.\n",
      "Cleaned data for coal:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing coal. Database saved as coal_energy_data.db.\n",
      "\n",
      "Database nonRenewables_energy_data.db already exists. Deleting it...\n",
      "Database nonRenewables_energy_data.db has been deleted.\n",
      "Processing dataset: nonRenewables\n",
      "Adding 'Country' column.\n",
      "Cleaned data for nonRenewables:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing nonRenewables. Database saved as nonRenewables_energy_data.db.\n",
      "\n",
      "Database renewables_energy_data.db already exists. Deleting it...\n",
      "Database renewables_energy_data.db has been deleted.\n",
      "Processing dataset: renewables\n",
      "Adding 'Country' column.\n",
      "Cleaned data for renewables:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing renewables. Database saved as renewables_energy_data.db.\n",
      "\n",
      "Database geothermal_energy_data.db already exists. Deleting it...\n",
      "Database geothermal_energy_data.db has been deleted.\n",
      "Processing dataset: geothermal\n",
      "Adding 'Country' column.\n",
      "Cleaned data for geothermal:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing geothermal. Database saved as geothermal_energy_data.db.\n",
      "\n",
      "Database hydro_energy_data.db already exists. Deleting it...\n",
      "Database hydro_energy_data.db has been deleted.\n",
      "Processing dataset: hydro\n",
      "Adding 'Country' column.\n",
      "Cleaned data for hydro:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing hydro. Database saved as hydro_energy_data.db.\n",
      "\n",
      "Database naturalGas_energy_data.db already exists. Deleting it...\n",
      "Database naturalGas_energy_data.db has been deleted.\n",
      "Processing dataset: naturalGas\n",
      "Adding 'Country' column.\n",
      "Cleaned data for naturalGas:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing naturalGas. Database saved as naturalGas_energy_data.db.\n",
      "\n",
      "Database nuclear_energy_data.db already exists. Deleting it...\n",
      "Database nuclear_energy_data.db has been deleted.\n",
      "Processing dataset: nuclear\n",
      "Adding 'Country' column.\n",
      "Cleaned data for nuclear:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing nuclear. Database saved as nuclear_energy_data.db.\n",
      "\n",
      "Database oil_energy_data.db already exists. Deleting it...\n",
      "Database oil_energy_data.db has been deleted.\n",
      "Processing dataset: oil\n",
      "Adding 'Country' column.\n",
      "Cleaned data for oil:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing oil. Database saved as oil_energy_data.db.\n",
      "\n",
      "Database otherRenewables_energy_data.db already exists. Deleting it...\n",
      "Database otherRenewables_energy_data.db has been deleted.\n",
      "Processing dataset: otherRenewables\n",
      "Adding 'Country' column.\n",
      "Cleaned data for otherRenewables:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing otherRenewables. Database saved as otherRenewables_energy_data.db.\n",
      "\n",
      "Database solar_energy_data.db already exists. Deleting it...\n",
      "Database solar_energy_data.db has been deleted.\n",
      "Processing dataset: solar\n",
      "Adding 'Country' column.\n",
      "Cleaned data for solar:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing solar. Database saved as solar_energy_data.db.\n",
      "\n",
      "Database wind_energy_data.db already exists. Deleting it...\n",
      "Database wind_energy_data.db has been deleted.\n",
      "Processing dataset: wind\n",
      "Adding 'Country' column.\n",
      "Cleaned data for wind:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing wind. Database saved as wind_energy_data.db.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function to process the datasets and create individual databases\n",
    "process_energy_data_individual_db(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Summary\n",
    "\n",
    "1.\tStep 1: Check and Create the SQLite Database:\n",
    "â€¢\tFor each dataset (coal, wind, etc.), the function checks if a corresponding SQLite database already exists. If it does, the existing database file is deleted to ensure a clean slate.\n",
    "2.\tStep 2: Load Data from Excel:\n",
    "â€¢\tThe energy data from the respective Excel file (e.g., coal, wind, etc.) is loaded into a Pandas DataFrame.\n",
    "3.\tStep 3: Store Data in the SQLite Database:\n",
    "â€¢\tThe raw data is stored in an individual SQLite database for each dataset. For example, coal_energy_data.db, wind_energy_data.db, etc.\n",
    "4.\tStep 4: Remove the First Two Rows:\n",
    "â€¢\tThe first two rows, typically containing metadata or irrelevant headers, are removed using SQL commands.\n",
    "5.\tStep 5: Drop Unnecessary Columns:\n",
    "â€¢\tAny columns with names starting with â€˜Unnamedâ€™ are dropped by selecting only the necessary columns.\n",
    "6.\tStep 6: Replace Invalid Values:\n",
    "â€¢\tInvalid values (:) are replaced with NULL in SQL to clean the data.\n",
    "7.\tStep 7: Rename Columns to Date Format:\n",
    "â€¢\tThe columns are renamed to proper date formats (e.g., 2016-01, 2024-07). If a Country column is missing, it is added and the cleaned table is created with the updated column names.\n",
    "8.\tStep 8: Query and Verify:\n",
    "â€¢\tThe first few rows of the cleaned data are queried from each database to verify the cleaning steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One database, multiple tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_energy_data_single_db(file_paths):\n",
    "    \"\"\"\n",
    "    This function processes energy production data for multiple datasets (coal, geothermal, wind, etc.)\n",
    "    by loading data from Excel, cleaning it, and saving each dataset as a separate table in a single SQLite database.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_paths: Dictionary containing dataset names and file paths.\n",
    "    \"\"\"\n",
    "    \n",
    "    db_name = 'energySources.db'  # Single database for all energy sources\n",
    "    \n",
    "    # Step 1: Check if the database file exists, delete if it does\n",
    "    if os.path.exists(db_name):\n",
    "        print(f\"Database {db_name} already exists. Deleting it...\")\n",
    "        os.remove(db_name)  # Delete the existing database file\n",
    "        print(f\"Database {db_name} has been deleted.\")\n",
    "    \n",
    "    # Now create a new SQLite connection for the single database\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    for dataset, file_path in file_paths.items():\n",
    "        print(f\"Processing dataset: {dataset}\")\n",
    "        \n",
    "        # Step 2: Load data from Excel\n",
    "        data = pd.read_excel(file_path, sheet_name=dataset, skiprows=range(0, 8))\n",
    "        \n",
    "        # Step 3: Store the raw data as a table in the SQLite database\n",
    "        data.to_sql(f'{dataset}', conn, if_exists='replace', index=False)\n",
    "        \n",
    "        # Step 4: Remove the first two rows\n",
    "        cursor.execute(f\"DELETE FROM {dataset} WHERE ROWID IN (1, 2);\")\n",
    "        conn.commit()\n",
    "        \n",
    "        # Step 5: Drop columns where the name starts with 'Unnamed'\n",
    "        cursor.execute(f\"PRAGMA table_info({dataset});\")\n",
    "        columns_info = cursor.fetchall()\n",
    "        columns_to_keep = [col[1] for col in columns_info if not col[1].startswith('Unnamed')]\n",
    "        \n",
    "        # Create a new table with only the required columns\n",
    "        cursor.execute(f\"\"\"\n",
    "            CREATE TABLE {dataset}_cleaned_v2 AS\n",
    "            SELECT {', '.join(columns_to_keep)}\n",
    "            FROM {dataset};\n",
    "        \"\"\")\n",
    "        cursor.execute(f\"DROP TABLE {dataset};\")\n",
    "        conn.commit()\n",
    "        \n",
    "        # Step 6: Replace invalid values (':' -> NULL)\n",
    "        for column in columns_to_keep[1:]:  # Skip 'Country' column\n",
    "            cursor.execute(f\"\"\"\n",
    "                UPDATE {dataset}_cleaned_v2\n",
    "                SET \"{column}\" = NULLIF(\"{column}\", ':');\n",
    "            \"\"\")\n",
    "        conn.commit()\n",
    "        \n",
    "        # Step 7: Rename columns with date formats (2016-01, 2016-02, ..., 2024-07)\n",
    "        date_columns = pd.date_range(start='2016-01', end='2024-07', freq='MS').strftime('%Y-%m').tolist()\n",
    "        \n",
    "        # Ensure the columns_to_keep matches the new date columns\n",
    "        new_columns = ['Country'] + date_columns\n",
    "\n",
    "        # Check if \"Country\" column exists in the cleaned table\n",
    "        cursor.execute(f\"PRAGMA table_info({dataset}_cleaned_v2);\")\n",
    "        columns_info = cursor.fetchall()\n",
    "        if \"Country\" not in [col[1] for col in columns_info]:\n",
    "            print(f\"Adding 'Country' column to dataset {dataset}.\")\n",
    "            # Recreate the table with the 'Country' column\n",
    "            cursor.execute(f\"\"\"\n",
    "                CREATE TABLE {dataset}_cleaned_temp AS\n",
    "                SELECT \"TIME\" AS Country, * FROM {dataset}_cleaned_v2;\n",
    "            \"\"\")\n",
    "            cursor.execute(f\"DROP TABLE {dataset}_cleaned_v2;\")\n",
    "            cursor.execute(f\"\"\"\n",
    "                CREATE TABLE {dataset}_cleaned_v2 AS\n",
    "                SELECT Country, * FROM {dataset}_cleaned_temp;\n",
    "            \"\"\")\n",
    "            cursor.execute(f\"DROP TABLE {dataset}_cleaned_temp;\")\n",
    "        conn.commit()\n",
    "        \n",
    "        # Rename columns by recreating the table with the updated date-based column names\n",
    "        cursor.execute(f\"\"\"\n",
    "            CREATE TABLE {dataset}_cleaned_final AS\n",
    "            SELECT Country, {', '.join([f'\"{old_col}\" AS \"{new_col}\"' for old_col, new_col in zip(columns_to_keep[1:], date_columns)])}\n",
    "            FROM {dataset}_cleaned_v2;\n",
    "        \"\"\")\n",
    "        \n",
    "        # Drop the intermediate table and rename the final table back to the original cleaned table\n",
    "        cursor.execute(f\"DROP TABLE {dataset}_cleaned_v2;\")\n",
    "        cursor.execute(f\"ALTER TABLE {dataset}_cleaned_final RENAME TO {dataset}_cleaned;\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Step 8: Query and verify the cleaned data\n",
    "        df_cleaned = pd.read_sql_query(f\"SELECT * FROM {dataset}_cleaned LIMIT 5;\", conn)\n",
    "        print(f\"Cleaned data for {dataset}:\")\n",
    "        print(df_cleaned)\n",
    "        \n",
    "    # Close the connection after processing all datasets\n",
    "    conn.close()\n",
    "    print(f\"Finished processing all datasets. Database saved as {db_name}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database energySources.db already exists. Deleting it...\n",
      "Database energySources.db has been deleted.\n",
      "Processing dataset: coal\n",
      "Adding 'Country' column to dataset coal.\n",
      "Cleaned data for coal:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Processing dataset: nonRenewables\n",
      "Adding 'Country' column to dataset nonRenewables.\n",
      "Cleaned data for nonRenewables:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Processing dataset: renewables\n",
      "Adding 'Country' column to dataset renewables.\n",
      "Cleaned data for renewables:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Processing dataset: geothermal\n",
      "Adding 'Country' column to dataset geothermal.\n",
      "Cleaned data for geothermal:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Processing dataset: hydro\n",
      "Adding 'Country' column to dataset hydro.\n",
      "Cleaned data for hydro:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Processing dataset: naturalGas\n",
      "Adding 'Country' column to dataset naturalGas.\n",
      "Cleaned data for naturalGas:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Processing dataset: nuclear\n",
      "Adding 'Country' column to dataset nuclear.\n",
      "Cleaned data for nuclear:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Processing dataset: oil\n",
      "Adding 'Country' column to dataset oil.\n",
      "Cleaned data for oil:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Processing dataset: otherRenewables\n",
      "Adding 'Country' column to dataset otherRenewables.\n",
      "Cleaned data for otherRenewables:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Processing dataset: solar\n",
      "Adding 'Country' column to dataset solar.\n",
      "Cleaned data for solar:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Processing dataset: wind\n",
      "Adding 'Country' column to dataset wind.\n",
      "Cleaned data for wind:\n",
      "    Country  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  \\\n",
      "0   Belgium     2015     2014     2013     2012     2011     2010     2009   \n",
      "1  Bulgaria     2015     2014     2013     2012     2011     2010     2009   \n",
      "2   Czechia     2015     2014     2013     2012     2011     2010     2009   \n",
      "3   Denmark     2015     2014     2013     2012     2011     2010     2009   \n",
      "4   Germany     2015     2014     2013     2012     2011     2010     2009   \n",
      "\n",
      "   2016-08  2016-09  ...  2023-10  2023-11  2023-12  2024-01  2024-02  \\\n",
      "0     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "1     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "2     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "3     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "4     2008     2007  ...     2013     2012     2011     2023     2022   \n",
      "\n",
      "   2024-03  2024-04  2024-05  2024-06  2024-07  \n",
      "0     2021     2020     2019     2018     2017  \n",
      "1     2021     2020     2019     2018     2017  \n",
      "2     2021     2020     2019     2018     2017  \n",
      "3     2021     2020     2019     2018     2017  \n",
      "4     2021     2020     2019     2018     2017  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "Finished processing all datasets. Database saved as energySources.db.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function to process the datasets into a single database with multiple tables\n",
    "process_energy_data_single_db(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of tables inside the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database:\n",
      "coal_cleaned\n",
      "nonRenewables_cleaned\n",
      "renewables_cleaned\n",
      "geothermal_cleaned\n",
      "hydro_cleaned\n",
      "naturalGas_cleaned\n",
      "nuclear_cleaned\n",
      "oil_cleaned\n",
      "otherRenewables_cleaned\n",
      "solar_cleaned\n",
      "wind_cleaned\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have a connection\n",
    "db_name = 'energySources.db'\n",
    "\n",
    "# Open a new connection if needed\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Step to check the tables inside the database\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Print the tables in the database\n",
    "print(\"Tables in the database:\")\n",
    "for table in tables:\n",
    "    print(table[0])\n",
    "\n",
    "# Close the connection once done\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference Between Individual Databases and Tables in a Single Database:\n",
    "\n",
    "In this case, we created multiple tables inside a single SQLite database (energySources.db), with each energy source (coal, geothermal, etc.) being stored as a table within that database.\n",
    "\n",
    "* **Advantages of using a single database with multiple tables**:\n",
    "\n",
    "\t* Simplified Querying: You can easily query data across different energy sources within a single connection.\n",
    "\t* Centralized Management: All data is stored in one file, making it easier to back up, manage, and share.\n",
    "\t* Easier Cross-Dataset Analysis: By having multiple tables in one database, you can perform SQL joins, unions, and other queries across different datasets more efficiently.\n",
    "\n",
    "* **Advantages of Separate Databases**:\n",
    "\n",
    "\t* Data Isolation: Each dataset is fully isolated, which can be useful for security or performance reasons.\n",
    "\t* Smaller Files: Each database will be smaller, which might make it easier to handle backups and manage files separately.\n",
    "\n",
    "In scenarios where you frequently need to analyze or compare data across different datasets (such as comparing coal and wind energy), having multiple tables inside a single database is more practical. If the datasets are independent or very large, separate databases might be preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations in DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL + Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will cover a step-by-step example to integrate the energy production data stored in a database (SQLite) and then using Python to analyze and plot the data. This guide walks through each step, from loading CSV data into an SQLite database to querying and plotting the energy production data for different countries.\n",
    "\n",
    "This sections includes downloading the data from individual `.csv` files, loading them into a SQLite database, and visualizing the energy production using Python.\n",
    "\n",
    "This guide shows how to:\n",
    "1. Download CSV files from Eurostat.\n",
    "2. Load data into a SQLite database.\n",
    "3. Use Python to query and visualize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download the Data from Eurostat\n",
    "\n",
    "The datasets are available on the Eurostat website under [Energy Statistics](https://ec.europa.eu/eurostat/web/energy). Letâ€™s assume the data files have been downloaded and stored in your `~/Downloads` folder as `.csv` files.\n",
    "\n",
    "For this example, we are using the following datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euroStat_coal_filePath = '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_coal.xlsx'\n",
    "euroStat_nonRenewables_filePath = '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_combustionFuels_nonRenewables.xlsx'\n",
    "euroStat_renewables_filePath = '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_combustionFuels_Renewables.xlsx'\n",
    "euroStat_geothermal_filePath = '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_geothermal.xlsx'\n",
    "euroStat_hydro_filePath = '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_hydro.xlsx'\n",
    "euroStat_naturalGas_filePath = '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_naturalGas.xlsx'\n",
    "euroStat_nuclear_filePath = '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_nuclear.xlsx'\n",
    "euroStat_oil_filePath = '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_oil.xlsx'\n",
    "euro_otherRenewables_filePath = '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_otherRenewables.xlsx'\n",
    "euroStat_solar_filePath = '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_solar.xlsx'\n",
    "euroStat_wind_filePath = '../data/section4/euroStat/nrg_cb_pem_page_spreadsheet_wind.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Data into SQLite Database\n",
    "\n",
    "We'll now read the downloaded CSV files, clean the data, and store them in an SQLite database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code for Loading CSV Files into SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .xlsx file\n",
    "euroStat_coal = pd.read_excel(euroStat_coal_filePath, sheet_name='coal', skiprows=range(0, 8))\n",
    "euroStat_nonRenewables = pd.read_excel(euroStat_nonRenewables_filePath, sheet_name='nonRenewables', skiprows=range(0, 8))\n",
    "euroStat_renewables = pd.read_excel(euroStat_renewables_filePath, sheet_name='renewables', skiprows=range(0, 8))\n",
    "euroStat_geothermal = pd.read_excel(euroStat_geothermal_filePath, sheet_name='geothermal', skiprows=range(0, 8))\n",
    "euroStat_hydro = pd.read_excel(euroStat_hydro_filePath, sheet_name='hydro', skiprows=range(0, 8))\n",
    "euroStat_naturalGas = pd.read_excel(euroStat_naturalGas_filePath, sheet_name='naturalGas', skiprows=range(0, 8))\n",
    "euroStat_nuclear = pd.read_excel(euroStat_nuclear_filePath, sheet_name='nuclear', skiprows=range(0, 8))\n",
    "euroStat_oil = pd.read_excel(euroStat_oil_filePath, sheet_name='oil', skiprows=range(0, 8))\n",
    "euro_otherRenewables = pd.read_excel(euro_otherRenewables_filePath, sheet_name='otherRenewables', skiprows=range(0, 8))\n",
    "euroStat_solar = pd.read_excel(euroStat_solar_filePath, sheet_name='solar', skiprows=range(0, 8))\n",
    "euroStat_wind = pd.read_excel(euroStat_wind_filePath, sheet_name='wind', skiprows=range(0, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>2016-01</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>2016-02</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>2016-03</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>2016-04</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>2016-05</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 196</th>\n",
       "      <th>2024-03</th>\n",
       "      <th>Unnamed: 198</th>\n",
       "      <th>2024-04</th>\n",
       "      <th>Unnamed: 200</th>\n",
       "      <th>2024-05</th>\n",
       "      <th>Unnamed: 202</th>\n",
       "      <th>2024-06</th>\n",
       "      <th>Unnamed: 204</th>\n",
       "      <th>2024-07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEO (Labels)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>European Union - 27 countries (from 2020)</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23110.523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179.131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>519.203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290.517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czechia</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2159.708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1550.964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1480.491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        TIME 2016-01  Unnamed: 2 2016-02  \\\n",
       "0                               GEO (Labels)     NaN         NaN     NaN   \n",
       "1  European Union - 27 countries (from 2020)       :         NaN       :   \n",
       "2                                    Belgium       :         NaN       :   \n",
       "3                                   Bulgaria       :         NaN       :   \n",
       "4                                    Czechia       :         NaN       :   \n",
       "\n",
       "   Unnamed: 4 2016-03  Unnamed: 6 2016-04  Unnamed: 8 2016-05  ...  \\\n",
       "0         NaN     NaN         NaN     NaN         NaN     NaN  ...   \n",
       "1         NaN       :         NaN       :         NaN       :  ...   \n",
       "2         NaN       :         NaN       :         NaN       :  ...   \n",
       "3         NaN       :         NaN       :         NaN       :  ...   \n",
       "4         NaN       :         NaN       :         NaN       :  ...   \n",
       "\n",
       "   Unnamed: 196    2024-03  Unnamed: 198   2024-04  Unnamed: 200   2024-05  \\\n",
       "0           NaN        NaN           NaN       NaN           NaN       NaN   \n",
       "1           NaN  23110.523           NaN         :           NaN         :   \n",
       "2           NaN    160.492           NaN   168.435           NaN   179.131   \n",
       "3           NaN    519.203           NaN    360.31           NaN   290.517   \n",
       "4           NaN   2159.708           NaN  1550.964           NaN  1480.491   \n",
       "\n",
       "   Unnamed: 202 2024-06  Unnamed: 204 2024-07  \n",
       "0           NaN     NaN           NaN     NaN  \n",
       "1           NaN       :           NaN       :  \n",
       "2           NaN       :           NaN       :  \n",
       "3           NaN       :           NaN       :  \n",
       "4           NaN       :           NaN       :  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "euroStat_coal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite database (it will be created if it doesn't exist)\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add the euroStat_coal dataset to the database using SQL\n",
    "euroStat_coal.to_sql('euroStat_coal', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths and dataset names\n",
    "datasets = ['coal', 'nonRenewables', 'renewables', 'geothermal', 'hydro', 'naturalGas', 'nuclear', 'oil', 'otherRenewables', 'solar', 'wind']\n",
    "data_path = os.path.expanduser('~/Downloads/')  # Path where the CSV files are downloaded\n",
    "db_path = 'energy_data.db'  # SQLite database file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    csv_file = os.path.join(data_path, f'{dataset}.csv')\n",
    "    df = pd.read_csv(csv_file, skiprows=1)  # Assuming the first row is metadata\n",
    "\n",
    "    # Rename columns properly (example: replace unnamed columns with actual month names)\n",
    "    df.columns = ['Country'] + [f'Month_{i+1}' for i in range(len(df.columns)-1)]\n",
    "\n",
    "    # Store each DataFrame in a table named after the dataset (e.g., 'wind', 'geothermal')\n",
    "    df.to_sql(dataset, conn, if_exists='replace', index=False)\n",
    "\n",
    "    print(f\"Data from {dataset}.csv loaded into the {dataset} table.\")\n",
    "\n",
    "# Commit and close the database connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "1. **Loading CSV Files**: We read each CSV file and load it into a pandas DataFrame, assuming the first row is metadata.\n",
    "2. **Cleaning Data**: We rename the columns, as some columns might be unnamed.\n",
    "3. **Storing in SQLite**: Each dataset is saved as a table in the SQLite database. For example, the `wind.csv` file will be saved in a table named `wind`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Query and Analyze the Data\n",
    "\n",
    "Now that weâ€™ve stored the data in an SQLite database, we can query it using SQL and visualize it in Python. Letâ€™s start by analyzing and plotting the wind energy production data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code for Querying and Plotting Wind Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconnect to the SQLite database\n",
    "conn = sqlite3.connect('energy_data.db')\n",
    "\n",
    "# Query wind energy data\n",
    "wind_query = \"\"\"\n",
    "SELECT * FROM wind;\n",
    "\"\"\"\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "wind_data = pd.read_sql_query(wind_query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Preview the data\n",
    "print(wind_data.head())\n",
    "\n",
    "# Example plotting wind energy production for Belgium\n",
    "country = 'Belgium'\n",
    "\n",
    "# Extract the data for Belgium (replace : and NaN values with 0 for simplicity)\n",
    "wind_belgium = wind_data[wind_data['Country'] == country].fillna(0)\n",
    "\n",
    "# Transpose to have months on x-axis\n",
    "months = wind_belgium.columns[1:]  # Skip the 'Country' column\n",
    "energy_values = wind_belgium.iloc[0, 1:]  # Skip the 'Country' column\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(months, energy_values, marker='o')\n",
    "plt.title(f'Wind Energy Production in {country} (MWh)')\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Energy Generated (MWh)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "1. **Query Data**: We query the `wind` table and load the data into a pandas DataFrame.\n",
    "2. **Data Cleaning**: We fill missing values (`NaN` or `:` in the dataset) with `0` for simplicity.\n",
    "3. **Plotting**: We plot the wind energy production for Belgium over the months using `matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Plotting Energy Production for Multiple Countries\n",
    "\n",
    "You can extend this example to plot data for multiple countries or compare the production of different renewable energy sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Code to Plot Energy Production for Multiple Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for comparing wind energy production of Belgium, Germany, and Spain\n",
    "countries = ['Belgium', 'Germany', 'Spain']\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for country in countries:\n",
    "    country_data = wind_data[wind_data['Country'] == country].fillna(0)\n",
    "    energy_values = country_data.iloc[0, 1:]  # Skip the 'Country' column\n",
    "    \n",
    "    plt.plot(months, energy_values, marker='o', label=country)\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.title('Wind Energy Production in Belgium, Germany, and Spain (MWh)')\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Energy Generated (MWh)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "1. **Multiple Countries**: We loop through a list of countries (e.g., Belgium, Germany, Spain) and plot their wind energy production on the same graph for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Summary\n",
    "\n",
    "1. **Downloading and Loading Data**: We downloaded the CSV files from Eurostat and loaded them into an SQLite database.\n",
    "2. **Querying the Database**: We queried specific tables from the database using SQL queries in Python.\n",
    "3. **Visualizing the Data**: We plotted the renewable energy production data (wind in this case) using matplotlib to visualize the monthly energy production for different countries.\n",
    "\n",
    "This approach allows you to easily handle large datasets, store them in a database, and perform complex analysis and visualization using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Summary\n",
    "\n",
    "In this section, we provided a detailed step-by-step guide to integrating renewable energy production data stored in an SQLite database with Python for data analysis and visualization. The process includes downloading CSV files from the Eurostat website, loading them into an SQLite database using Python, and then querying the data for analysis and visualization.\n",
    "\n",
    "## Key Points Covered:\n",
    "\n",
    "1.\tData Download and Preparation: We downloaded the relevant CSV files for different renewable energy sources (wind, solar, geothermal, hydro, etc.) from Eurostat and stored them locally.\n",
    "2.\tLoading Data into SQLite: The downloaded CSV files were cleaned and stored in an SQLite database using the pandas and sqlite3 libraries in Python. Each dataset was stored in its own table within the database.\n",
    "3.\tQuerying the Data: We queried the SQLite database for specific data (e.g., wind energy production) using SQL commands within Python.\n",
    "4.\tVisualizing Data: Using matplotlib, we created plots of the energy production data (e.g., wind energy production in Belgium) across different months.\n",
    "5.\tComparison Across Countries: We extended the example to compare the energy production of multiple countries on a single plot, allowing for better insights into trends and differences in renewable energy generation.\n",
    "\n",
    "## Lessons Learned\n",
    "\n",
    "1.\t**Handling Large Datasets**: By using `SQLite`, we can efficiently store and manage large datasets locally, allowing for easy querying and retrieval of data as needed.\n",
    "2.\t**Data Cleaning and Preparation**: Properly cleaning and formatting the data, such as renaming columns and filling missing values, is essential for accurate analysis.\n",
    "3.\t**SQL Integration with Python**: Using `SQL` within Python allows for powerful querying capabilities, which can be further extended by combining results with pandas for in-depth analysis.\n",
    "4.\t**Visualization**: Pythonâ€™s `matplotlib` library makes it easy to create visual representations of the data, helping to uncover trends and insights from complex datasets.\n",
    "5.\t**Scalability**: The approach can be easily extended to more complex datasets, multiple energy sources, or multiple countries, providing a scalable solution for energy data analysis."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
